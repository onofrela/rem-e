# Configuraci√≥n de LM Studio para Rem-E

Este documento explica c√≥mo configurar LM Studio para que funcione correctamente con la generaci√≥n de planes por IA.

## üìã Requisitos

- LM Studio instalado
- Un modelo de lenguaje descargado (ej: Llama, Mistral, Phi, etc.)

## üîß Configuraci√≥n Paso a Paso

### 1. Descargar un Modelo

1. Abre LM Studio
2. Ve a la pesta√±a **"Search"** o **"Models"**
3. Busca y descarga un modelo (recomendados):
   - `TheBloke/Mistral-7B-Instruct-v0.2-GGUF`
   - `TheBloke/Llama-2-7B-Chat-GGUF`
   - `microsoft/Phi-3-mini-4k-instruct-gguf`
4. Espera a que termine la descarga

### 2. Cargar el Modelo

1. Ve a la pesta√±a **"Chat"**
2. En la parte superior, selecciona el modelo que descargaste
3. El modelo se cargar√° en memoria

### 3. Iniciar el Servidor Local

1. Ve a la pesta√±a **"Local Server"** o **"Developer"**
2. **IMPORTANTE:** Busca y habilita la opci√≥n **"Enable CORS"** o **"Allow Cross-Origin Requests"**
   - Si no ves esta opci√≥n, busca en Settings/Preferences
3. Haz clic en **"Start Server"**
4. Verifica que diga:
   ```
   Server running at: http://localhost:1234
   ```

### 4. Verificar la Configuraci√≥n

Puedes verificar que el servidor funciona correctamente:

1. Abre tu navegador
2. Ve a: `http://localhost:1234/v1/models`
3. Deber√≠as ver una respuesta JSON con los modelos disponibles

**Si ves un error CORS**, sigue la secci√≥n de soluci√≥n de problemas.

## üêõ Soluci√≥n de Problemas

### Error: "Failed to fetch" o "CORS blocked"

**Causa:** LM Studio no tiene CORS habilitado, o el navegador est√° bloqueando la petici√≥n.

**Soluciones:**

#### Soluci√≥n 1: Configurar CORS en LM Studio (Preferida)

1. En LM Studio, ve a **Settings** ‚Üí **Server**
2. Busca **"CORS Settings"** o **"Network Settings"**
3. Habilita **"Allow all origins"** o agrega `http://localhost:3000`
4. Reinicia el servidor

#### Soluci√≥n 2: Usar un Proxy Local (Si CORS no est√° disponible)

Si LM Studio no tiene opci√≥n de CORS, puedes usar un proxy simple.

**Crear archivo `proxy-lmstudio.js`:**

```javascript
const http = require('http');
const httpProxy = require('http-proxy');

const proxy = httpProxy.createProxyServer({});

const server = http.createServer((req, res) => {
  // Habilitar CORS
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'GET, POST, OPTIONS');
  res.setHeader('Access-Control-Allow-Headers', 'Content-Type');

  if (req.method === 'OPTIONS') {
    res.writeHead(200);
    res.end();
    return;
  }

  // Proxy a LM Studio
  proxy.web(req, res, {
    target: 'http://localhost:1234',
    changeOrigin: true,
  });
});

server.listen(1235, () => {
  console.log('Proxy corriendo en http://localhost:1235');
  console.log('Redirigiendo a LM Studio en http://localhost:1234');
});
```

**Instalar dependencias:**
```bash
npm install http-proxy
```

**Ejecutar el proxy:**
```bash
node proxy-lmstudio.js
```

**Actualizar `.env.local`:**
```env
NEXT_PUBLIC_LM_STUDIO_URL=http://localhost:1235
```

### Error: "Model not loaded"

**Causa:** No hay ning√∫n modelo cargado en LM Studio.

**Soluci√≥n:**
1. Ve a la pesta√±a "Chat" en LM Studio
2. Selecciona un modelo del dropdown
3. Espera a que se cargue completamente
4. Vuelve a la pesta√±a "Server" y verifica que est√© corriendo

### El servidor no inicia

**Causa:** El puerto 1234 ya est√° en uso.

**Soluci√≥n:**
1. En LM Studio, ve a Settings
2. Cambia el puerto a otro (ej: 1235)
3. Actualiza `.env.local`:
   ```env
   NEXT_PUBLIC_LM_STUDIO_URL=http://localhost:1235
   ```

## ‚úÖ Verificaci√≥n Final

Una vez configurado:

1. LM Studio debe mostrar: **"Server running"**
2. En Rem-E, ve a **Planificador** ‚Üí **Describir con IA**
3. Escribe algo como: *"Quiero un plan vegetariano para 2 personas"*
4. Haz clic en **"Generar Plan"**
5. Deber√≠as ver el plan generado en unos segundos

## üîó Enlaces √ötiles

- [LM Studio Download](https://lmstudio.ai/)
- [LM Studio Documentation](https://lmstudio.ai/docs)
- [Troubleshooting CORS](https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS)
