# ğŸ¤ Asistente de Voz Rem-E

## ğŸ“‹ DescripciÃ³n General

El asistente de voz de Rem-E utiliza la **Web Speech API nativa del navegador** (sin servidores externos ni Vosk) para reconocimiento de voz, combinado con **LM Studio** para procesamiento de lenguaje natural con capacidades de function calling.

### Arquitectura

```
Usuario â†’ Web Speech API â†’ useVoiceNavigation Hook â†’ Clasificador de Intent
                                                              â†“
                                           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                           â†“                                     â†“
                                    NavegaciÃ³n                              Pregunta
                                    (Next.js Router)                   (API /api/assistant)
                                                                              â†“
                                                                       LM Studio + Functions
                                                                              â†“
                                                                    Handlers (IndexedDB)
```

---

## ğŸš€ CÃ³mo Funciona

### 1. ActivaciÃ³n con Wake Word

Di **"Rem-E"** seguido de tu comando o pregunta:

```
âœ… "Rem-E, Â¿quÃ© tengo en el inventario?"
âœ… "Rem-E, ve a recetas"
âœ… "Rem-E, Â¿cuÃ¡ntos tomates tengo?"
âœ… "Rem-E, Â¿quÃ© puedo cocinar con pollo?"
```

### 2. ClasificaciÃ³n AutomÃ¡tica de Intents

El sistema clasifica automÃ¡ticamente si tu comando es:

#### ğŸ§­ **NavegaciÃ³n**
- Contiene verbos de navegaciÃ³n: "ve a", "abre", "muestra", "navega"
- Menciona secciones especÃ­ficas: "recetas", "inventario", "inicio", "planificaciÃ³n"

**Ejemplos:**
```
â†’ "ve a recetas"          â†’ Navega a /recipes
â†’ "abre inventario"       â†’ Navega a /inventory
â†’ "muestra mi cocina"     â†’ Navega a /kitchen
â†’ "inicio"                â†’ Navega a /
```

#### â“ **Pregunta/Consulta**
- Contiene palabras interrogativas: "quÃ©", "cuÃ¡nto", "cÃ³mo", "dÃ³nde", "cuÃ¡l"
- Verbos como: "tengo", "hay", "puedo", "necesito", "busca", "dame"

**Ejemplos:**
```
â†’ "Â¿quÃ© tengo en el inventario?"           â†’ Llama API del asistente
â†’ "Â¿cuÃ¡ntos tomates tengo?"                â†’ Llama getInventory + bÃºsqueda
â†’ "Â¿quÃ© puedo cocinar con pollo?"          â†’ Llama getRecipesByIngredients
â†’ "busca recetas de pasta"                 â†’ Llama searchRecipes
```

#### ğŸ³ **Comandos de Cocina** (cuando estÃ¡s en guÃ­a de receta)
- "siguiente", "anterior", "repetir", "pausar", "reanudar", "timer"

---

## ğŸ”§ TecnologÃ­as Utilizadas

### Frontend (Cliente)
- **Web Speech API** (`webkitSpeechRecognition`): Reconocimiento de voz nativo del navegador
  - Soportado en: Chrome, Edge, Safari (iOS/macOS)
  - **No requiere servidores externos**
  - Funciona en mÃ³viles y tablets con permisos de micrÃ³fono

- **useVoiceNavigation Hook**: Maneja:
  - DetecciÃ³n de wake word ("Rem-E")
  - ClasificaciÃ³n de intents (navegaciÃ³n vs pregunta)
  - Llamadas a la API del asistente
  - GestiÃ³n de errores y estados

### Backend (Servidor Next.js)
- **`/api/assistant`**: Endpoint que procesa preguntas
  - Recibe texto del usuario + contexto
  - Llama a LM Studio con function calling
  - Ejecuta funciones localmente (IndexedDB)
  - Retorna respuesta en lenguaje natural

- **LM Studio**: LLM local con function calling
  - Ejecuta en `http://localhost:1234`
  - Modelo recomendado: Llama 3.1 8B o similar
  - Tiene acceso a 50+ funciones de cocina

- **Function Handlers**: Ejecutan acciones en IndexedDB
  - `getInventory`: Obtiene inventario del usuario
  - `searchRecipes`: Busca recetas
  - `addToInventory`: Agrega ingredientes
  - Y mÃ¡s...

---

## ğŸ“ Ejemplos de Uso

### NavegaciÃ³n
```
Usuario: "Rem-E, ve a recetas"
â†’ Sistema navega a /recipes

Usuario: "Rem-E, abre inventario"
â†’ Sistema navega a /inventory
```

### Consultas al Inventario
```
Usuario: "Rem-E, Â¿quÃ© tengo en el inventario?"
â†’ [thinking...]
â†’ "Tienes 12 ingredientes: tomates, cebollas, pollo..."

Usuario: "Rem-E, Â¿cuÃ¡ntos tomates tengo?"
â†’ [thinking...]
â†’ [Llama getInventory â†’ Busca "tomate"]
â†’ "Tienes 3 tomates en la alacena"
```

### BÃºsqueda de Recetas
```
Usuario: "Rem-E, Â¿quÃ© puedo cocinar con pollo?"
â†’ [thinking...]
â†’ [Llama getInventory â†’ getRecipesByIngredients]
â†’ "Puedes hacer Pollo al Horno, Sopa de Pollo, y Tacos de Pollo"

Usuario: "Rem-E, busca recetas de pasta"
â†’ [thinking...]
â†’ [Llama searchRecipes]
â†’ "EncontrÃ© 5 recetas de pasta: Carbonara, Alfredo..."
```

### Comandos de Cocina (en guÃ­a de receta)
```
Usuario: [cocinando] "siguiente"
â†’ Avanza al siguiente paso

Usuario: [cocinando] "Rem-E, Â¿cÃ³mo pico finamente?"
â†’ [thinking...]
â†’ [Llama explainCookingStep con contexto del paso actual]
â†’ "Para picar finamente, sujeta el cuchillo con firmeza..."
```

---

## ğŸ› ï¸ ConfiguraciÃ³n

### Requisitos

1. **Navegador compatible**:
   - Chrome/Edge (desktop y mÃ³vil)
   - Safari (iOS/macOS)
   - Firefox (experimental, puede requerir flags)

2. **LM Studio** ejecutÃ¡ndose localmente:
   ```bash
   # Descargar desde: https://lmstudio.ai
   # Cargar modelo (ej: Llama 3.1 8B)
   # Iniciar servidor local en puerto 1234
   ```

3. **HTTPS o localhost**:
   - La Web Speech API requiere conexiÃ³n segura
   - Funciona en `http://localhost:3000`
   - En producciÃ³n requiere HTTPS

### Permisos de MicrÃ³fono

#### Desktop
- El navegador pedirÃ¡ permisos automÃ¡ticamente
- Acepta el permiso cuando se muestre el diÃ¡logo

#### MÃ³vil/Tablet
1. Toca el botÃ³n del micrÃ³fono para activar
2. El navegador pedirÃ¡ permisos
3. Acepta el permiso en el diÃ¡logo
4. Si no funciona, verifica:
   - **iOS**: Ajustes > Safari > MicrÃ³fono
   - **Android**: Ajustes > Chrome > Permisos > MicrÃ³fono

---

## ğŸ› Troubleshooting

### "Navegador no compatible"
- **Causa**: Tu navegador no soporta Web Speech API
- **SoluciÃ³n**: Usa Chrome, Edge o Safari

### "MicrÃ³fono denegado"
- **Causa**: No diste permisos de micrÃ³fono
- **SoluciÃ³n Desktop**: Haz clic en el Ã­cono del candado (ğŸ”’) en la barra de direcciones â†’ Permisos â†’ MicrÃ³fono â†’ Permitir
- **SoluciÃ³n MÃ³vil**: Ve a Ajustes del navegador â†’ Permisos â†’ MicrÃ³fono â†’ Permitir para este sitio

### "No puedo conectar con LM Studio"
- **Causa**: LM Studio no estÃ¡ corriendo o no estÃ¡ en el puerto 1234
- **SoluciÃ³n**:
  1. Abre LM Studio
  2. Carga un modelo
  3. Ve a "Developer" â†’ "Start Server"
  4. Verifica que estÃ© en `http://localhost:1234`

### El asistente solo hace navegaciones
- **Causa**: Este era el problema original - ahora estÃ¡ ARREGLADO
- **SoluciÃ³n**: La nueva versiÃ³n de `useVoiceNavigation` ya tiene integraciÃ³n con el LLM

### El asistente no responde preguntas
- **Causa**: LM Studio no estÃ¡ disponible o hay error en la clasificaciÃ³n
- **SoluciÃ³n**:
  1. Verifica que LM Studio estÃ© corriendo
  2. Abre la consola del navegador (F12) y busca errores
  3. Verifica que la pregunta tenga palabras interrogativas ("quÃ©", "cuÃ¡nto", etc.)

---

## ğŸ”„ Flujo Completo de una Consulta

```
1. Usuario dice: "Rem-E, Â¿quÃ© tengo en el inventario?"
   â†“
2. Web Speech API detecta el audio
   â†“
3. useVoiceNavigation detecta wake word "Rem-E"
   â†“
4. Extrae comando: "Â¿quÃ© tengo en el inventario?"
   â†“
5. classifyIntent detecta que es PREGUNTA (contiene "quÃ©" y "tengo")
   â†“
6. processQuestion llama a /api/assistant con:
   {
     text: "Â¿quÃ© tengo en el inventario?",
     context: { currentPage: "/", ... }
   }
   â†“
7. API /api/assistant:
   - Construye prompt con SYSTEM_PROMPT + contexto
   - Llama a LM Studio con tools disponibles
   - LM Studio decide llamar a getInventory()
   â†“
8. executeFunction ejecuta getInventory en IndexedDB
   â†“
9. LM Studio recibe resultado y genera respuesta natural:
   "Tienes 12 ingredientes en total: 3 tomates en la alacena, 2 cebollas..."
   â†“
10. useVoiceNavigation muestra la respuesta en VoiceAssistant
    â†“
11. Usuario ve/escucha la respuesta
```

---

## ğŸ¯ Mejoras Futuras

- [ ] Soporte para conversaciones continuas (sin wake word despuÃ©s de cada pregunta)
- [ ] Text-to-Speech para leer respuestas en voz alta
- [ ] Soporte multiidioma
- [ ] Mejores visualizaciones de funciones ejecutadas
- [ ] Modo offline con fallback a comandos bÃ¡sicos
- [ ] IntegraciÃ³n con ngrok para usar LLM remoto

---

## ğŸ“š Referencias

- [Web Speech API](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)
- [LM Studio](https://lmstudio.ai)
- [OpenAI Function Calling](https://platform.openai.com/docs/guides/function-calling)
